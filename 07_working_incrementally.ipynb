{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Users\n",
    "\n",
    "Ok, the main point of this chapter is to go from our state of assuming that all users will share a common to-do list on the site to the state where we support multiple independent users.  The injunction with which we begin is, as always in this book, to consider first how we would confirm that whatever implementation we choose to realize this goal *is* in fact successful.\n",
    "\n",
    "Here's an interesting point: he suggests that our functional tests file represents the closest thing that we have for a design document for this project.  I like that way of looking at the TDD paradigm: rather than keeping everything scattered and nebulous in your mind, you could be using the files storing your functional tests as a way to plan around the project; what should go where."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functional_tests/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functional_tests/tests.py\n",
    "from django.test import LiveServerTestCase\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "MAX_WAIT = 10\n",
    "\n",
    "class NewVisitorTest(LiveServerTestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.browser = webdriver.Firefox()\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.browser.quit()\n",
    "\n",
    "    def wait_for_row_in_list_table(self, row_text):\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                table = self.browser.find_element_by_id('id_list_table')\n",
    "                rows = table.find_elements_by_tag_name('tr')\n",
    "                self.assertIn(row_text, [row.text for row in rows])\n",
    "                return\n",
    "            except (AssertionError, WebDriverException) as e:\n",
    "                if time.time() - start_time > MAX_WAIT:\n",
    "                    raise e\n",
    "                time.sleep(0.5)\n",
    "\n",
    "    def test_can_start_a_list_and_retrieve_it_later(self):\n",
    "        # Edith has heard about a cool new online to-do app.  She goes\n",
    "        # to check out its homepage\n",
    "        self.browser.get(self.live_server_url)\n",
    "\n",
    "        # She notices the page title and header mention to-do lists\n",
    "        self.assertIn('To-Do', self.browser.title)\n",
    "        header_text = self.browser.find_element_by_tag_name('h1').text\n",
    "        self.assertIn('To-Do', header_text)\n",
    "\n",
    "        # She is invited to enter a to-do item straight away\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        self.assertEqual(\n",
    "            inputbox.get_attribute('placeholder'),\n",
    "            'Enter a to-do item'\n",
    "        )\n",
    "\n",
    "        # She types \"Buy peacock feathers\" into a text box \n",
    "        # (Edith's hobby is tying fly-fishing lures)\n",
    "        inputbox.send_keys('Buy peacock feathers')\n",
    "\n",
    "        # When she hits enter, the page updates, and now the page lists\n",
    "        # \"1: Buy peacock feathers\" as an item in a to-do list table\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "        self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
    "\n",
    "        # There is still a text box inviting her to add another item.\n",
    "        # She enters \"Use peacock feathers to make a fly\"\n",
    "        # (Edith is very methodical)\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        inputbox.send_keys('Use peacock feathers to make a fly')\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "\n",
    "        # The page updates again, and now shows both items on her list\n",
    "        self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
    "        self.wait_for_row_in_list_table('2: Use peacock feathers to make a fly')\n",
    "\n",
    "        # Edith wonders whether the site will remember her list.  Then she sees\n",
    "        # that the site has generated a unique URL for her -- there is some \n",
    "        # explanatory text to that effect.\n",
    "        self.fail('Finish the test!')\n",
    "\n",
    "        # She visits that URL - her to-do list is still there.\n",
    "\n",
    "        # Satisfied, she goes back to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agile vs. \"Big Design Up Front\"\n",
    "\n",
    "Ok, another interesting point about design philosophy follows immediately.  Harry says that the traditional way to tackle large engineering projects would be to try to plan everything out with paper (or at least schematic software), figuring out where everything should go before you start writing code.  TDD, on the other hand, was derived from or otherwise aligned with the [AGILE design movement](https://en.wikipedia.org/wiki/Agile_software_development), which emphasizes incremental, iterative design, rather than figuring you can make an overarching plan from the very get-go that will prove very robust to complications encountered when coding up the details.  Basically, get your hands dirty early on, and expect the need to refactor.\n",
    "\n",
    "Of course, the advocated answer is still not really to just dive in mindlessly, rather, it's to think in mid-sized, modular chunks.  The emphasis is on delivering a \"minimal viable product\", getting it in the field where you can collect real-world feedback about its reception.  Furthermore, this mindset is meant to counter the temptation to add on additional features and functionality that you might envision in a \"perfect\" or otherwise optimal app.  The initialism is \"**YAGNI**\", for \"you ain't gonna need it\": let the users tell you if something is lacking.\n",
    "\n",
    "In this case, the plan to support multiple users involves having the server return customized URLs for each user, so they see different content based on the recognition of their particular credentials, and thus previously stored list items.\n",
    "\n",
    "\n",
    "## REST\n",
    "\n",
    "There's another term here, the REST (Representational State Transfer) API paradigm, which sounds like its gist is that the URL returned for any part of a web app/site should reflect the \"data structure\" of the content.  In practice, Harry suggests that the trailing part of the URL for a to-do list should contain:\n",
    "\n",
    "* `lists/new` for a page that accepts POST requests to generate new lists\n",
    "* `lists/list_name` to view the contents of an existing list\n",
    "* `lists/list_name/add_item` for a page that accepts POST requests to add to a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "He suggests that refactoring to support multiple users will involve creating an entirely new functional test; not sure yet if that means a new file, a new class in our existing module, or just new methods within the existing class.  ...Ok, it is quickly revealed that it's the latter option: new methods tacked on to our existing setup.  Ah, ok, but also some refactoring of existing ones; we're not just going to leave in place the soon-to-be-irrelevant methods that assumed that all visitors to the site shared one list.  So some shuffling around of code within the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting functional_tests/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile functional_tests/tests.py\n",
    "from django.test import LiveServerTestCase\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import WebDriverException\n",
    "import time\n",
    "import unittest\n",
    "\n",
    "MAX_WAIT = 10\n",
    "\n",
    "class NewVisitorTest(LiveServerTestCase):\n",
    "\n",
    "    def setUp(self):\n",
    "        self.browser = webdriver.Firefox()\n",
    "\n",
    "    def tearDown(self):\n",
    "        self.browser.quit()\n",
    "\n",
    "    def wait_for_row_in_list_table(self, row_text):\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                table = self.browser.find_element_by_id('id_list_table')\n",
    "                rows = table.find_elements_by_tag_name('tr')\n",
    "                self.assertIn(row_text, [row.text for row in rows])\n",
    "                return\n",
    "            except (AssertionError, WebDriverException) as e:\n",
    "                if time.time() - start_time > MAX_WAIT:\n",
    "                    raise e\n",
    "                time.sleep(0.5)\n",
    "\n",
    "    def test_can_start_a_list_for_one_user(self):\n",
    "        # Edith has heard about a cool new online to-do app.  She goes\n",
    "        # to check out its homepage\n",
    "        self.browser.get(self.live_server_url)\n",
    "\n",
    "        # She notices the page title and header mention to-do lists\n",
    "        self.assertIn('To-Do', self.browser.title)\n",
    "        header_text = self.browser.find_element_by_tag_name('h1').text\n",
    "        self.assertIn('To-Do', header_text)\n",
    "\n",
    "        # She is invited to enter a to-do item straight away\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        self.assertEqual(\n",
    "            inputbox.get_attribute('placeholder'),\n",
    "            'Enter a to-do item'\n",
    "        )\n",
    "\n",
    "        # She types \"Buy peacock feathers\" into a text box \n",
    "        # (Edith's hobby is tying fly-fishing lures)\n",
    "        inputbox.send_keys('Buy peacock feathers')\n",
    "\n",
    "        # When she hits enter, the page updates, and now the page lists\n",
    "        # \"1: Buy peacock feathers\" as an item in a to-do list table\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "        self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
    "\n",
    "        # There is still a text box inviting her to add another item.\n",
    "        # She enters \"Use peacock feathers to make a fly\"\n",
    "        # (Edith is very methodical)\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        inputbox.send_keys('Use peacock feathers to make a fly')\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "\n",
    "        # The page updates again, and now shows both items on her list\n",
    "        self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
    "        self.wait_for_row_in_list_table('2: Use peacock feathers to make a fly')\n",
    "\n",
    "        # Satisfied, she goes back to sleep\n",
    "\n",
    "    def test_multiple_users_can_start_lists_at_different_urls(self):\n",
    "        # Edith starts a new to-do list\n",
    "        self.browser.get(self.live_server_url)\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        inputbox.send_keys('Buy peacock feathers')\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "        self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
    "\n",
    "        # She notices that her list has a unique URL\n",
    "        edith_list_url = self.browser.current_url\n",
    "        self.assertRegex(edith_list_url, '/lists/.+')\n",
    "\n",
    "        # Now a new user, Francis, comes along to the site.\n",
    "\n",
    "        ## We use a new browser session to make sure that no information\n",
    "        ## of Edith's is coming through from cookies, etc.\n",
    "        self.browser.quit()\n",
    "        self.browser = webdriver.Firefox()\n",
    "\n",
    "        # Francis visits the home page.  There is no sign of Edith's list\n",
    "        self.browser.get(self.live_server_url)\n",
    "        page_text = self.browser.find_element_by_tag_name('body').text\n",
    "        self.assertNotIn('Buy peacock feathers', page_text)\n",
    "        self.assertNotIn('make a fly', page_text)\n",
    "\n",
    "        # Francis starts a new list by entering a new item.\n",
    "        # He is less intersting than Edith...\n",
    "        inputbox = self.browser.find_element_by_id('id_new_item')\n",
    "        inputbox.send_keys('Buy milk')\n",
    "        inputbox.send_keys(Keys.ENTER)\n",
    "        self.wait_for_row_in_list_table('1: Buy milk')\n",
    "\n",
    "        # Francis gets his own unique URL\n",
    "        francis_list_url = self.browser.current_url\n",
    "        self.assertRegex(francis_list_url, '/lists.+')\n",
    "        self.assertNotEqual(francis_list_url, edith_list_url)\n",
    "\n",
    "        # Again, there is no trace of Edith's list\n",
    "        page_text = self.browser.find_element_by_tag_name('body').text\n",
    "        self.assertNotIn('Buy peacock feathers', page_text)\n",
    "        self.assertIn('Buy milk', page_text)\n",
    "\n",
    "        # Satisfied, they both go back to sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harry explains that the double-hash-mark lines represent *meta-comments*, which is really a bit of an aside to the dev reviewing the test, explaining *why* a particular step is being coded into the test that the user themselves wouldn't necessarily execute.  It's breaking the flow of assuming that the comments and code all represent a user's experience in navigating the site.  Here, it's assumed that another dev wouldn't understand why we're closing the browser (because it's not yet clear that a separate user is about to come on).\n",
    "\n",
    "Now we run the modified functional test, hoping that `test_can_start_a_list_for_one_user` passes and `test_multiple_users_can_start_lists_at_different_urls` will fail..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".F\n",
      "======================================================================\n",
      "FAIL: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 80, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.assertRegex(edith_list_url, '/lists/.+')\n",
      "AssertionError: Regex didn't match: '/lists/.+' not found in 'http://localhost:64258/'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 15.636s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test functional_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that *is* the outcome anticipated by the text.  He suggests a commit to the remote repo at this point.\n",
    "\n",
    "\n",
    "# Increments... again\n",
    "\n",
    "We rehash the main objectives summarized for addressing this chapter:\n",
    "\n",
    "1. Adjust the \"model\" of the website so that items are associated with unique lists\n",
    "2. Make unique URLs for each list\n",
    "3. A unique URL for generating new lists\n",
    "4. A unique URL for *adding* items to extant lists\n",
    "\n",
    "And Harry says that the effect of the error encountered above is indicating that the second item isn't working yet.  Specifically, we aren't being redirected as expected after a POST request is issued.  We need to change the location expected when redirected in the `test_redirects_after_post` method of the **unit tests**, and since we haven't succeeded yet in breaking out the model into unique lists for every user, he suggests a placeholder value that's obviously inadequate to the final purpose: \"`the-only-list-in-the-world`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/tests.py\n",
    "from django.test import TestCase\n",
    "from lists.models import Item\n",
    "\n",
    "class HomePageTest(TestCase):\n",
    "\n",
    "    def test_home_page_returns_correct_html(self):\n",
    "        response = self.client.get('/')\n",
    "        self.assertTemplateUsed(response, 'home.html')\n",
    "\n",
    "    def test_can_save_a_POST_request(self):\n",
    "        self.client.post('/', data={'item_text': 'A new list item'})\n",
    "\n",
    "        self.assertEqual(Item.objects.count(), 1)\n",
    "        new_item = Item.objects.first()\n",
    "        self.assertEqual(new_item.text, 'A new list item')\n",
    "\n",
    "    def test_redirects_after_POST(self):\n",
    "        response = self.client.post('/', data={'item_text': 'A new list item'})\n",
    "        self.assertEqual(response.status_code, 302)\n",
    "        self.assertEqual(\n",
    "            response['location'], '/lists/the-only-list-in-the-world'\n",
    "        )\n",
    "\n",
    "    def test_only_saves_items_when_necessary(self):\n",
    "        self.client.get('/')\n",
    "        self.assertEqual(Item.objects.count(), 0)\n",
    "\n",
    "    def test_displays_all_list_items(self):\n",
    "        Item.objects.create(text='itemey 1')\n",
    "        Item.objects.create(text='itemey 2')\n",
    "\n",
    "        response = self.client.get('/')\n",
    "\n",
    "        self.assertIn('itemey 1', response.content.decode())\n",
    "        self.assertIn('itemey 2', response.content.decode())\n",
    "\n",
    "\n",
    "class ItemModelTest(TestCase):\n",
    "    \n",
    "    def test_saving_and_retrieving_items(self):\n",
    "        first_item = Item()\n",
    "        first_item.text = 'The first (ever) list item'\n",
    "        first_item.save()\n",
    "\n",
    "        second_item = Item()\n",
    "        second_item.text = 'Item the second'\n",
    "        second_item.save()\n",
    "\n",
    "        saved_items = Item.objects.all()\n",
    "        self.assertEqual(saved_items.count(), 2)\n",
    "\n",
    "        first_saved_item = saved_items[0]\n",
    "        second_saved_item = saved_items[1]\n",
    "        self.assertEqual(first_saved_item.text, 'The first (ever) list item')\n",
    "        self.assertEqual(second_saved_item.text, 'Item the second')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this case, we modified line #21 of the unit tests file.  And, apparently, we now anticipate this test will fail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....F.\n",
      "======================================================================\n",
      "FAIL: test_redirects_after_POST (lists.tests.HomePageTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 21, in test_redirects_after_POST\n",
      "    response['location'], '/lists/the-only-list-in-the-world'\n",
      "AssertionError: '/' != '/lists/the-only-list-in-the-world'\n",
      "- /\n",
      "+ /lists/the-only-list-in-the-world\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.038s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having confirmed that the unit test does indeed yield the expected failure, he says we can proceed to modifying the dev script, specifically the `views` file which determines which URL to return after POSTing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/views.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/views.py\n",
    "from django.shortcuts import redirect, render\n",
    "from lists.models import Item\n",
    "\n",
    "def home_page(request):\n",
    "    if request.method == 'POST':\n",
    "        Item.objects.create(text=request.POST['item_text'])\n",
    "        return redirect('/lists/the-only-list-in-the-world')\n",
    "\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'home.html', {'items': items})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the unit test now passes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.033s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the functional tests break, because the page doesn't exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......EE\n",
      "======================================================================\n",
      "ERROR: test_can_start_a_list_for_one_user (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 55, in test_can_start_a_list_for_one_user\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 76, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 34.655s\n",
      "\n",
      "FAILED (errors=2)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He notes that the fact that an older test, which was previously passing, now fails, is known as a *regression*.  Kind of perversely, he suggests ameliorating the situation by actually *making* a page known as `the-only-list-in-the-world`.  Sounds ridiculous to me, but I guess the supposed advantage is that having the infrastructure in place to constitute a fix will ultimately be expanded and repurposed to serve as the *actual* content of the site in the future, when we're ready to get around to that.\n",
    "\n",
    "The proposed solution in this case involves creating a new class in the `lists/tests.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/tests.py\n",
    "from django.test import TestCase\n",
    "from lists.models import Item\n",
    "\n",
    "class HomePageTest(TestCase):\n",
    "\n",
    "    def test_home_page_returns_correct_html(self):\n",
    "        response = self.client.get('/')\n",
    "        self.assertTemplateUsed(response, 'home.html')\n",
    "\n",
    "    def test_can_save_a_POST_request(self):\n",
    "        self.client.post('/', data={'item_text': 'A new list item'})\n",
    "\n",
    "        self.assertEqual(Item.objects.count(), 1)\n",
    "        new_item = Item.objects.first()\n",
    "        self.assertEqual(new_item.text, 'A new list item')\n",
    "\n",
    "    def test_redirects_after_POST(self):\n",
    "        response = self.client.post('/', data={'item_text': 'A new list item'})\n",
    "        self.assertEqual(response.status_code, 302)\n",
    "        self.assertEqual(\n",
    "            response['location'], '/lists/the-only-list-in-the-world'\n",
    "        )\n",
    "\n",
    "    def test_only_saves_items_when_necessary(self):\n",
    "        self.client.get('/')\n",
    "        self.assertEqual(Item.objects.count(), 0)\n",
    "\n",
    "    def test_displays_all_list_items(self):\n",
    "        Item.objects.create(text='itemey 1')\n",
    "        Item.objects.create(text='itemey 2')\n",
    "\n",
    "        response = self.client.get('/')\n",
    "\n",
    "        self.assertIn('itemey 1', response.content.decode())\n",
    "        self.assertIn('itemey 2', response.content.decode())\n",
    "\n",
    "\n",
    "class ItemModelTest(TestCase):\n",
    "    \n",
    "    def test_saving_and_retrieving_items(self):\n",
    "        first_item = Item()\n",
    "        first_item.text = 'The first (ever) list item'\n",
    "        first_item.save()\n",
    "\n",
    "        second_item = Item()\n",
    "        second_item.text = 'Item the second'\n",
    "        second_item.save()\n",
    "\n",
    "        saved_items = Item.objects.all()\n",
    "        self.assertEqual(saved_items.count(), 2)\n",
    "\n",
    "        first_saved_item = saved_items[0]\n",
    "        second_saved_item = saved_items[1]\n",
    "        self.assertEqual(first_saved_item.text, 'The first (ever) list item')\n",
    "        self.assertEqual(second_saved_item.text, 'Item the second')\n",
    "\n",
    "\n",
    "class ListViewTest(TestCase):\n",
    "\n",
    "    def test_displays_all_items(self):\n",
    "        Item.objects.create(text='itemey 1')\n",
    "        Item.objects.create(text='itemey 2')\n",
    "\n",
    "        response = self.client.get('/lists/the-only-list-in-the-world/')\n",
    "\n",
    "        self.assertContains(response, 'itemey 1')\n",
    "        self.assertContains(response, 'itemey 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He points out that one new change here is getting away from the more verbose `assertIn` and `response.content.decode` approaches, and instead utilizing the `assertContains` method contained within Django, \"*which knows how to deal with responses and the bytes of their content*\".\n",
    "\n",
    "Retry the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......FEE\n",
      "======================================================================\n",
      "ERROR: test_can_start_a_list_for_one_user (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 55, in test_can_start_a_list_for_one_user\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 76, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_displays_all_items (lists.tests.ListViewTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 66, in test_displays_all_items\n",
      "    self.assertContains(response, 'itemey 1')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\testcases.py\", line 385, in assertContains\n",
      "    response, text, status_code, msg_prefix, html)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\testcases.py\", line 357, in _assert_contains\n",
      "    \" (expected %d)\" % (response.status_code, status_code)\n",
      "AssertionError: 404 != 200 : Couldn't retrieve content: Response code was 404 (expected 200)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 40.377s\n",
      "\n",
      "FAILED (failures=1, errors=2)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He says that the `assertContains` helps you pick out more detail from the resulting tests, that it can tell that the response code is 404, which is just because we haven't implemented the URL.\n",
    "\n",
    "\n",
    "## A New URL\n",
    "\n",
    "We implement this by editing the `superlists/urls.py` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting superlists/urls.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile superlists/urls.py\n",
    "from django.conf.urls import url\n",
    "from lists import views\n",
    "\n",
    "urlpatterns = [\n",
    "    url(r'^$', views.home_page, name='home'),\n",
    "    url(\n",
    "        r'^lists/the-only-list-in-the-world/$', views.view_list, name='view_list'\n",
    "    ),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's new there is the eighth line (noting that because I don't remember having checked out that file's contents before).\n",
    "\n",
    "Rerun the test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture func_test\n",
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......EEE\n",
      "======================================================================\n",
      "ERROR: test_displays_all_items (lists.tests.ListViewTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 64, in test_displays_all_items\n",
      "    response = self.client.get('/lists/the-only-list-in-the-world/')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 536, in get\n",
      "    **extra)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 340, in get\n",
      "    return self.generic('GET', path, secure=secure, **r)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 416, in generic\n",
      "    return self.request(**r)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 501, in request\n",
      "    six.reraise(*exc_info)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\utils\\six.py\", line 686, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\core\\handlers\\exception.py\", line 41, in inner\n",
      "    response = get_response(request)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\core\\handlers\\base.py\", line 198, in _get_response\n",
      "    \"returned None instead.\" % (callback.__module__, view_name)\n",
      "ValueError: The view lists.views.view_list didn't return an HttpResponse object. It returned None instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lines = func_test.stderr.split('\\n')\n",
    "# print('\\n'.join(lines[-5:]))\n",
    "\n",
    "print('\\n'.join(lines[:len(lines) // 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New View Function\n",
    "\n",
    "Kind of unexpectedly, Harry recommends addressing this issue by just adding an empty function to the `views` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/views.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/views.py\n",
    "from django.shortcuts import redirect, render\n",
    "from lists.models import Item\n",
    "\n",
    "def home_page(request):\n",
    "    if request.method == 'POST':\n",
    "        Item.objects.create(text=request.POST['item_text'])\n",
    "        return redirect('/lists/the-only-list-in-the-world')\n",
    "\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'home.html', {'items': items})\n",
    "\n",
    "def view_list(request):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture func_test_1\n",
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 34.128s\n",
      "\n",
      "FAILED (errors=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(func_test.stderr[-500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......EEE\n",
      "======================================================================\n",
      "ERROR: test_displays_all_items (lists.tests.ListViewTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 64, in test_displays_all_items\n",
      "    response = self.client.get('/lists/the-only-list-in-the-world/')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 536, in get\n",
      "    **extra)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 340, in get\n",
      "    return self.generic('GET', path, secure=secure, **r)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 416, in generic\n",
      "    return self.request(**r)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\client.py\", line 501, in request\n",
      "    six.reraise(*exc_info)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\utils\\six.py\", line 686, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\core\\handlers\\exception.py\", line 41, in inner\n",
      "    response = get_response(request)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\core\\handlers\\base.py\", line 198, in _get_response\n",
      "    \"returned None instead.\" % (callback.__module__, view_name)\n",
      "ValueError: The view lists.views.view_list didn't return an HttpResponse object. It returned None instead.\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_can_start_a_list_for_one_user (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 55, in test_can_start_a_list_for_one_user\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "======================================================================\n",
      "ERROR: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 76, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.wait_for_row_in_list_table('1: Buy peacock feathers')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 22, in wait_for_row_in_list_table\n",
      "    table = self.browser.find_element_by_id('id_list_table')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 360, in find_element_by_id\n",
      "    return self.find_element(by=By.ID, value=id_)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 978, in find_element\n",
      "    'value': value})['value']\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\", line 321, in execute\n",
      "    self.error_handler.check_response(response)\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\", line 242, in check_response\n",
      "    raise exception_class(message, screen, stacktrace)\n",
      "selenium.common.exceptions.NoSuchElementException: Message: Unable to locate element: [id=\"id_list_table\"]\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 34.284s\n",
      "\n",
      "FAILED (errors=3)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print(func_test_1.stderr[-500:])\n",
    "print(func_test_1.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm.  I'm getting a different output than him; the book says that the number of `errors` should be down to `1` at this point, but I'm still seeing three.  In fact, I don't see any meaningful difference in the `stderr`s before versus after implementing the empty function.\n",
    "\n",
    "Well, anyways, then he says to just paste a couple lines from the `home_page` view into the new `view_list` view, so that it isn't quite so empty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/views.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/views.py\n",
    "from django.shortcuts import redirect, render\n",
    "from lists.models import Item\n",
    "\n",
    "def home_page(request):\n",
    "    if request.method == 'POST':\n",
    "        Item.objects.create(text=request.POST['item_text'])\n",
    "        return redirect('/lists/the-only-list-in-the-world')\n",
    "\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'home.html', {'items': items})\n",
    "\n",
    "def view_list(request):\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'home.html', {'items': items})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture func_test_2\n",
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......FF\n",
      "======================================================================\n",
      "FAIL: test_can_start_a_list_for_one_user (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 66, in test_can_start_a_list_for_one_user\n",
      "    self.wait_for_row_in_list_table('2: Use peacock feathers to make a fly')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 24, in wait_for_row_in_list_table\n",
      "    self.assertIn(row_text, [row.text for row in rows])\n",
      "AssertionError: '2: Use peacock feathers to make a fly' not found in ['1: Buy peacock feathers']\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 92, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.assertNotIn('Buy peacock feathers', page_text)\n",
      "AssertionError: 'Buy peacock feathers' unexpectedly found in 'Your To-Do list\\n1: Buy peacock feathers'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 33.637s\n",
      "\n",
      "FAILED (failures=2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(func_test_2.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we're back in accord with the text in terms of outputs, at least.  And the nature of what's being reported is a little less basic, so he suggests we would at this point really have to pay more attention to what it's saying, in order to figure out what we'd need to do next in order to get the tests to pass.\n",
    "\n",
    "It's complaining about what happens when we try to add a second item to the list, so we can be pretty confident that the first item checks out.\n",
    "\n",
    "He also notes that the unit tests should be passing at this point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced)."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.032s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Destroying test database for alias 'default'...\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harry says that a rule of thumb is that when all unit tests pass but the functional ones don't, it's often a problem with your templates.\n",
    "\n",
    "In this case, the minimal home page HTML template doesn't specify what URL to POST to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load lists/templates/home.html\n",
    "<html>\n",
    "    <head>\n",
    "        <title>To-Do lists</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Your To-Do list</h1>\n",
    "        <form method=\"POST\">\n",
    "            <input name=\"item_text\" id=\"id_new_item\" placeholder=\"Enter a to-do item\" />\n",
    "            {% csrf_token %}\n",
    "        </form>\n",
    "        <table id=\"id_list_table\">\n",
    "            {% for item in items %}\n",
    "                <tr><td> {{ forloop.counter }}: {{ item.text }}</td></tr>\n",
    "            {% endfor %}\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When that's the case, the POST request gets shunted by default back to the same URL that is currently loaded in the browser.  He says that you could change the view to include logic for handling POST requests to the new URL, too, but that that would necessitate writing a bunch of new tests, and that, instead, for his purposes at this point, it's sufficient to just tell your template file to explicitly direct the POST request to the homepage's URL (the base of the site's address, so just \"`/`\").  Specifically, you pass that to an \"`action`\" arg in the `form` tag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/templates/home.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/templates/home.html\n",
    "<html>\n",
    "    <head>\n",
    "        <title>To-Do lists</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Your To-Do list</h1>\n",
    "        <form method=\"POST\", action=\"/\">\n",
    "            <input name=\"item_text\" id=\"id_new_item\" placeholder=\"Enter a to-do item\" />\n",
    "            {% csrf_token %}\n",
    "        </form>\n",
    "        <table id=\"id_list_table\">\n",
    "            {% for item in items %}\n",
    "                <tr><td> {{ forloop.counter }}: {{ item.text }}</td></tr>\n",
    "            {% endfor %}\n",
    "        </table>\n",
    "    </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture func_test_3\n",
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........F\n",
      "======================================================================\n",
      "FAIL: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 92, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.assertNotIn('Buy peacock feathers', page_text)\n",
      "AssertionError: 'Buy peacock feathers' unexpectedly found in 'Your To-Do list\\n1: Buy peacock feathers'\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 21.113s\n",
      "\n",
      "FAILED (failures=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(func_test_3.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that resolves the \"*regression*\" mentioned earlier: that (while the new functionality is not yet working as intended) at least our older tests are back to passing.\n",
    "\n",
    "\n",
    "# Refactoring\n",
    "\n",
    "Harry now advocates taking another look at our unit tests file at this point, and seeing if there are things we no longer need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!grep -E \"class|def\" lists/tests.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops; I forgot that this is running in the Windows OS context:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class HomePageTest(TestCase):\n",
      "    def test_home_page_returns_correct_html(self):\n",
      "    def test_can_save_a_POST_request(self):\n",
      "    def test_redirects_after_POST(self):\n",
      "    def test_only_saves_items_when_necessary(self):\n",
      "    def test_displays_all_list_items(self):\n",
      "class ItemModelTest(TestCase):\n",
      "    def test_saving_and_retrieving_items(self):\n",
      "class ListViewTest(TestCase):\n",
      "    def test_displays_all_items(self):\n"
     ]
    }
   ],
   "source": [
    "with open('lists/tests.py', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    if ('class' in line) or ('def' in line):\n",
    "        print(line, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He suggests that, of these, the `test_displays_all_list_items` method is no longer needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/tests.py\n",
    "from django.test import TestCase\n",
    "from lists.models import Item\n",
    "\n",
    "class HomePageTest(TestCase):\n",
    "\n",
    "    def test_home_page_returns_correct_html(self):\n",
    "        response = self.client.get('/')\n",
    "        self.assertTemplateUsed(response, 'home.html')\n",
    "\n",
    "    def test_can_save_a_POST_request(self):\n",
    "        self.client.post('/', data={'item_text': 'A new list item'})\n",
    "\n",
    "        self.assertEqual(Item.objects.count(), 1)\n",
    "        new_item = Item.objects.first()\n",
    "        self.assertEqual(new_item.text, 'A new list item')\n",
    "\n",
    "    def test_redirects_after_POST(self):\n",
    "        response = self.client.post('/', data={'item_text': 'A new list item'})\n",
    "        self.assertEqual(response.status_code, 302)\n",
    "        self.assertEqual(\n",
    "            response['location'], '/lists/the-only-list-in-the-world'\n",
    "        )\n",
    "\n",
    "    def test_only_saves_items_when_necessary(self):\n",
    "        self.client.get('/')\n",
    "        self.assertEqual(Item.objects.count(), 0)\n",
    "\n",
    "\n",
    "class ItemModelTest(TestCase):\n",
    "    \n",
    "    def test_saving_and_retrieving_items(self):\n",
    "        first_item = Item()\n",
    "        first_item.text = 'The first (ever) list item'\n",
    "        first_item.save()\n",
    "\n",
    "        second_item = Item()\n",
    "        second_item.text = 'Item the second'\n",
    "        second_item.save()\n",
    "\n",
    "        saved_items = Item.objects.all()\n",
    "        self.assertEqual(saved_items.count(), 2)\n",
    "\n",
    "        first_saved_item = saved_items[0]\n",
    "        second_saved_item = saved_items[1]\n",
    "        self.assertEqual(first_saved_item.text, 'The first (ever) list item')\n",
    "        self.assertEqual(second_saved_item.text, 'Item the second')\n",
    "\n",
    "\n",
    "class ListViewTest(TestCase):\n",
    "\n",
    "    def test_displays_all_items(self):\n",
    "        Item.objects.create(text='itemey 1')\n",
    "        Item.objects.create(text='itemey 2')\n",
    "\n",
    "        response = self.client.get('/lists/the-only-list-in-the-world/')\n",
    "\n",
    "        self.assertContains(response, 'itemey 1')\n",
    "        self.assertContains(response, 'itemey 2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.036s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we note that the number of unit tests reported as having been performed is reduced to 6.\n",
    "\n",
    "The next thing we recommend changing is to split out the functionality of the home page to be between prompting the user for new items to add, and another to simply display the current contents of a user's to-do list.  That involves creating a new template and, I suppose after that, either a new view or at least modifying the existing ones?\n",
    "\n",
    "First though (of course), we write the unit test to look for the new page that just shows contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/tests.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/tests.py\n",
    "from django.test import TestCase\n",
    "from lists.models import Item\n",
    "\n",
    "class HomePageTest(TestCase):\n",
    "\n",
    "    def test_home_page_returns_correct_html(self):\n",
    "        response = self.client.get('/')\n",
    "        self.assertTemplateUsed(response, 'home.html')\n",
    "\n",
    "    def test_can_save_a_POST_request(self):\n",
    "        self.client.post('/', data={'item_text': 'A new list item'})\n",
    "\n",
    "        self.assertEqual(Item.objects.count(), 1)\n",
    "        new_item = Item.objects.first()\n",
    "        self.assertEqual(new_item.text, 'A new list item')\n",
    "\n",
    "    def test_redirects_after_POST(self):\n",
    "        response = self.client.post('/', data={'item_text': 'A new list item'})\n",
    "        self.assertEqual(response.status_code, 302)\n",
    "        self.assertEqual(\n",
    "            response['location'], '/lists/the-only-list-in-the-world'\n",
    "        )\n",
    "\n",
    "    def test_only_saves_items_when_necessary(self):\n",
    "        self.client.get('/')\n",
    "        self.assertEqual(Item.objects.count(), 0)\n",
    "\n",
    "\n",
    "class ItemModelTest(TestCase):\n",
    "    \n",
    "    def test_saving_and_retrieving_items(self):\n",
    "        first_item = Item()\n",
    "        first_item.text = 'The first (ever) list item'\n",
    "        first_item.save()\n",
    "\n",
    "        second_item = Item()\n",
    "        second_item.text = 'Item the second'\n",
    "        second_item.save()\n",
    "\n",
    "        saved_items = Item.objects.all()\n",
    "        self.assertEqual(saved_items.count(), 2)\n",
    "\n",
    "        first_saved_item = saved_items[0]\n",
    "        second_saved_item = saved_items[1]\n",
    "        self.assertEqual(first_saved_item.text, 'The first (ever) list item')\n",
    "        self.assertEqual(second_saved_item.text, 'Item the second')\n",
    "\n",
    "\n",
    "class ListViewTest(TestCase):\n",
    "\n",
    "    def test_uses_list_template(self):\n",
    "        response = self.client.get('/lists/the-only-list-in-the-world/')\n",
    "        self.assertTemplateUsed(response, 'list.html')\n",
    "\n",
    "    def test_displays_all_items(self):\n",
    "        Item.objects.create(text='itemey 1')\n",
    "        Item.objects.create(text='itemey 2')\n",
    "\n",
    "        response = self.client.get('/lists/the-only-list-in-the-world/')\n",
    "\n",
    "        self.assertContains(response, 'itemey 1')\n",
    "        self.assertContains(response, 'itemey 2')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, just confirm that the new unit test fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......F\n",
      "======================================================================\n",
      "FAIL: test_uses_list_template (lists.tests.ListViewTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 53, in test_uses_list_template\n",
      "    self.assertTemplateUsed(response, 'list.html')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\testcases.py\", line 583, in assertTemplateUsed\n",
      "    % (template_name, ', '.join(template_names))\n",
      "AssertionError: False is not true : Template 'list.html' was not a template used to render the response. Actual template(s) used: home.html\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.041s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we change the view to serve up the new page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/views.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/views.py\n",
    "from django.shortcuts import redirect, render\n",
    "from lists.models import Item\n",
    "\n",
    "def home_page(request):\n",
    "    if request.method == 'POST':\n",
    "        Item.objects.create(text=request.POST['item_text'])\n",
    "        return redirect('/lists/the-only-list-in-the-world')\n",
    "\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'home.html', {'items': items})\n",
    "\n",
    "def view_list(request):\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'list.html', {'items': items})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which now points to a nonexisting template for the page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture unit_test_1\n",
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "template_name, chain=chain)\n",
      "django.template.exceptions.TemplateDoesNotExist: list.html\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.077s\n",
      "\n",
      "FAILED (errors=2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(unit_test_1.stderr[-200:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, he advocates just making an empty template file to correspond to what is sought according to the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lists/templates/list.html', 'w') as f:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".....F.\n",
      "======================================================================\n",
      "FAIL: test_displays_all_items (lists.tests.ListViewTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\lists\\tests.py\", line 61, in test_displays_all_items\n",
      "    self.assertContains(response, 'itemey 1')\n",
      "  File \"C:\\Users\\DCM0303\\Miniconda3\\envs\\test_dev_book\\lib\\site-packages\\django\\test\\testcases.py\", line 393, in assertContains\n",
      "    self.assertTrue(real_count != 0, msg_prefix + \"Couldn't find %s in response\" % text_repr)\n",
      "AssertionError: False is not true : Couldn't find 'itemey 1' in response\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.042s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which also matches up with the text at this point; so it's loading the thing, and it doesn't find the specific items in the list.\n",
    "\n",
    "Harry says that the needs at this point of what the old homepage template and the read-only list view page are similar enough that you can get started by just copying the `home.html` template file in place of the blank one we just made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lists/templates/list.html'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "shutil.copy('lists/templates/home.html', 'lists/templates/list.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that that gets your unit test back to passing (i.e., find \"`itemey_1`\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.033s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool.  Now, modify the contents of those templates; as mentioned, we're now envisioning the home page to just prompt you to... oh, I see.  The breakdown of intended functionality for the two pages is different than I stated above.  Rather than having the homepage load your list and prompt you to insert new items *without* showing the existing items, the default assumption is that it should prompt you to create an entirely new list.\n",
    "\n",
    "That means we can remove the lines ssaying to display the table, and further that we can change the header tag to prompt you to create a new list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/templates/home.html\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/templates/home.html\n",
    "<html>\n",
    "    <head>\n",
    "        <title>To-Do lists</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Start a new To-Do list</h1>\n",
    "        <form method=\"POST\", action=\"/\">\n",
    "            <input name=\"item_text\" id=\"id_new_item\" placeholder=\"Enter a to-do item\" />\n",
    "            {% csrf_token %}\n",
    "        </form>\n",
    "    </body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real quick re-run your unit tests to ensure that didn't break anything:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.041s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, since we're not displaying preexisting list items in the home page, we can modify the view function that's returning it to avoid reference to such content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting lists/views.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile lists/views.py\n",
    "from django.shortcuts import redirect, render\n",
    "from lists.models import Item\n",
    "\n",
    "def home_page(request):\n",
    "    if request.method == 'POST':\n",
    "        Item.objects.create(text=request.POST['item_text'])\n",
    "        return redirect('/lists/the-only-list-in-the-world')\n",
    "    return render(request, 'home.html')\n",
    "\n",
    "def view_list(request):\n",
    "    items = Item.objects.all()\n",
    "    return render(request, 'list.html', {'items': items})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".......\n",
      "----------------------------------------------------------------------\n",
      "Ran 7 tests in 0.032s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, proceed to checking on how the functional tests are faring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test database for alias 'default'...\n",
      "System check identified no issues (0 silenced).\n",
      "Destroying test database for alias 'default'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "........F\n",
      "======================================================================\n",
      "FAIL: test_multiple_users_can_start_lists_at_different_urls (functional_tests.tests.NewVisitorTest)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 100, in test_multiple_users_can_start_lists_at_different_urls\n",
      "    self.wait_for_row_in_list_table('1: Buy milk')\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 28, in wait_for_row_in_list_table\n",
      "    raise e\n",
      "  File \"c:\\Data\\projects\\test_driven_development\\functional_tests\\tests.py\", line 24, in wait_for_row_in_list_table\n",
      "    self.assertIn(row_text, [row.text for row in rows])\n",
      "AssertionError: '1: Buy milk' not found in ['1: Buy peacock feathers', '2: Buy milk']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 9 tests in 31.419s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    }
   ],
   "source": [
    "!python manage.py test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "He explains this outcome as saying that the experience of Francis' visit is marred by his added list item not showing up, and the site instead showing Edith's list (well, because we haven't actually implemented the dev code changes required to accommodate multiple users to the site).  So we've basically done all of thise legwork to restructure our project to *be ready to stage those important changes*, but haven't actually done it yet.\n",
    "\n",
    "Harry emphasizes at this point that you shouldn't take all the work in the first half of this chapter as useless or find the process too discouraging.  Our design assumption when starting the project, of delivering minimal viable product by making a site that was only ever intended for one user, is vastly different from a site serving many users.  That's a significant alteration, and you can't make it too hastily, so setting the stage to ensure your tests and project layout are ready for it is important.\n",
    "\n",
    "Accordingly, he suggests a commit to the repo at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "feed05ccc7eb225dc818f24e82979f91976c426d29a2051bc4ff0a12e22a2954"
  },
  "kernelspec": {
   "display_name": "Python 3.6.15 ('test_dev_book')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
